# The Empathy Engine üéôÔ∏è

A service that dynamically modulates the vocal characteristics of synthesized speech based on the detected emotion of the source text.

This project bridges the gap between text-based sentiment and expressive, human-like audio output by intelligently mapping emotions to voice parameters.

## Project Description

In the world of AI-driven voice interactions, standard Text-to-Speech (TTS) systems often sound robotic and lack emotional resonance. The Empathy Engine addresses this challenge by:

1. Detecting emotions in text using natural language processing
2. Dynamically adjusting voice parameters (rate, pitch, volume) based on the detected emotion
3. Generating more human-like speech that matches the emotional context of the text

The result is synthesized speech that can sound genuinely enthusiastic about good news, patient when explaining complex ideas, or empathetic when responding to frustrations.

## Core Features

1. **Text Input**: Accept text via a web interface or CLI
2. **Emotion Detection**: Analyze text to detect emotions and their intensity
3. **Voice Modulation**: Alter vocal parameters (rate, pitch, volume) based on detected emotions
4. **Audio Output**: Generate playable audio files (.mp3, .wav)

## Features

1. **Granular Emotion Detection**: Detects multiple emotional states:
   - happy, excited, sad, angry, fear, neutral, surprise, positive, negative, concerned
2. **Intensity Scaling**: Modulates voice parameters based on the intensity of the detected emotion (low, medium, high)
3. **Web Interface**: Provides a clean, intuitive interface with text input and an embedded audio player
4. **Multiple TTS Engines**: Supports various TTS engines:
   - pyttsx3 (offline, fast)
   - Google TTS (better quality)
   - ElevenLabs (premium quality, API key required)

## Technical Stack

- **Python**: Core language for all components
- **Emotion Analysis**: TextBlob (basic), HuggingFace Transformers (advanced)
- **TTS Engines**: pyttsx3, Google TTS (gTTS), ElevenLabs API
- **Web Framework**: Flask

## Setup and Installation

1. Clone the repository:
```bash
git clone https://github.com/yourusername/empathy-engine.git
cd empathy-engine
```

2. Create a virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

4. Download NLTK data (required for TextBlob):
```bash
python -c "import nltk; nltk.download('punkt'); nltk.download('vader_lexicon')"
```

5. (Optional) For premium voice quality with ElevenLabs:
   - Create an account at [ElevenLabs](https://beta.elevenlabs.io/)
   - Copy your API key from the account settings
   - Rename `.env.template` to `.env` and add your API key:
```
ELEVENLABS_API_KEY=your_elevenlabs_api_key_here
ELEVENLABS_VOICE_ID=21m00Tcm4TlvDq8ikWAM  # You can change this to other voice IDs
```

## Usage

### Command Line Interface

```bash
python src/cli.py --text "I am so excited about this new technology!" --output "output/speech.mp3"
```

### Web Interface

```bash
python src/app.py
```
Then open your browser and navigate to `http://127.0.0.1:5000`

![Empathy Engine Web Interface](https://raw.githubusercontent.com/MaheswarreddyPalugulla/-The-Empathy-Engine/main/screenshots/empathy_engine_ui.png)

<img src="screenshots/empathy_engine_ui.png" alt="Empathy Engine Web Interface" width="800"/>

### Public Access with Ngrok

To make the application accessible over the internet:

1. Ensure you have ngrok installed:
```bash
pip install pyngrok
```

2. Run the public server:
```bash
python src/simple_public_server.py
```

This will create a public URL that anyone can use to access your Empathy Engine. The URL will be displayed in the console output and will look something like `https://a1b2c3d4.ngrok.io`.

Note: Public URLs generated by ngrok's free tier are temporary and will change each time you restart the server.

## Design Choices

### Emotion Detection

The Empathy Engine uses a two-tier approach to emotion detection:

1. **Basic Sentiment Analysis**: Using TextBlob for fast, offline processing
   - Analyzes polarity (positive/negative) and subjectivity
   - Works without internet connection
   - Suitable for simple use cases

2. **Advanced Emotion Classification**: Using transformer models for nuanced detection
   - Detects specific emotions beyond positive/negative
   - Provides higher accuracy and granularity
   - Requires internet connection for initial model download

This tiered approach allows the system to fall back to basic analysis when needed while offering rich emotion detection when available.

### Emotion-to-Voice Mapping

The core innovation of the Empathy Engine is its emotion-to-voice parameter mapping. Each detected emotion translates to specific voice modifications:

| Emotion    | Rate    | Pitch   | Volume  | Description                          |
|------------|---------|---------|---------|--------------------------------------|
| happy      | +20%    | +15%    | +10%    | Faster, higher pitch, slightly louder|
| excited    | +30%    | +20%    | +15%    | Even faster and higher               |
| sad        | -10%    | -15%    | -10%    | Slower, lower pitch, slightly quieter|
| angry      | +10%    | +5%     | +20%    | Slightly faster, normal pitch, louder|
| fear       | +15%    | +10%    | -5%     | Faster, higher pitch, quieter        |
| neutral    | +0%     | +0%     | +0%     | No modification                      |
| surprise   | +15%    | +20%    | +15%    | Faster, higher pitch, louder         |
| positive   | +10%    | +10%    | +5%     | Slightly faster and higher           |
| negative   | -5%     | -5%     | -5%     | Slightly slower, lower, quieter      |
| concerned  | -5%     | -5%     | +5%     | Slower, lower, slightly louder       |

### Intensity Scaling

Beyond basic emotion mapping, the Empathy Engine also scales voice modulations based on the detected intensity of emotions:

- **Low intensity**: 50% of the standard parameter adjustments
- **Medium intensity**: 100% of the standard parameter adjustments
- **High intensity**: 150% of the standard parameter adjustments

This ensures proportional voice changes that match not just the type but the strength of the emotion expressed in the text.

### Multiple TTS Engine Support

The system supports three TTS engines with different characteristics:

1. **pyttsx3**: 
   - Local processing, no internet required
   - Fast execution
   - Limited voice quality

2. **Google TTS (gTTS)**:
   - Better voice quality
   - Requires internet connection
   - Limited control over voice parameters

3. **ElevenLabs**:
   - Premium voice quality
   - Advanced voice control
   - Requires API key and internet connection

This flexibility allows users to choose the appropriate balance between quality, speed, and connectivity requirements.

## Project Structure

The repository is organized as follows:

```
empathy_engine/
‚îú‚îÄ‚îÄ src/                      # Source code
‚îÇ   ‚îú‚îÄ‚îÄ app.py                # Flask web interface
‚îÇ   ‚îú‚îÄ‚îÄ cli.py                # Command line interface
‚îÇ   ‚îú‚îÄ‚îÄ emotion_detector.py   # Emotion detection logic
‚îÇ   ‚îú‚îÄ‚îÄ voice_modulator.py    # Voice parameter modulation
‚îÇ   ‚îî‚îÄ‚îÄ empathy_engine.py     # Main integration module
‚îú‚îÄ‚îÄ templates/                # HTML templates for web interface
‚îÇ   ‚îî‚îÄ‚îÄ index.html            # Main web interface
‚îú‚îÄ‚îÄ output/                   # Directory for generated audio files
‚îú‚îÄ‚îÄ .env.template             # Template for environment variables
‚îú‚îÄ‚îÄ requirements.txt          # Python dependencies
‚îî‚îÄ‚îÄ README.md                 # Project documentation
```

## Quick Start Guide

To get started with the Empathy Engine quickly:

1. **Install Dependencies**:
   ```
   pip install -r requirements.txt
   ```

2. **Run the Web Interface**:
   ```
   python src/app.py
   ```
   Then open your browser to http://127.0.0.1:5000/

3. **Use the CLI**:
   ```
   python src/cli.py --text "I am so excited about this new technology!" --output "output/speech.mp3" --voice male --engine pyttsx3
   ```

4. **For Premium Voices (ElevenLabs)**:
   - Copy `.env.template` to `.env`
   - Add your ElevenLabs API key to the `.env` file
   - Select ElevenLabs as the engine in the web interface, or specify `--engine elevenlabs` in the CLI
| Angry | +10% | +5% | +20% |
| Neutral | 0% | 0% | 0% |
| Surprised | +15% | +20% | +15% |
| Concerned | -5% | -5% | +5% |

## License

This project is licensed under the MIT License - see the LICENSE file for details.
